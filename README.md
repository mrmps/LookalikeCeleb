<p align="center">
  <img src="public/og.png" alt="Screenshot of LookalikeCeleb" width="640" style="border-radius:12px;box-shadow:0 4px 24px #0002">
</p>

<h1 align="center">ğŸ¬â€¯LookalikeCeleb</h1>
<p align="center"><strong>
  Find your celebrity twin with AI &nbsp;â€¢&nbsp; 100% openâ€‘source &nbsp;â€¢&nbsp; Powered by <a href="https://inference.net">Inference.net</a>
</strong></p>

<p align="center">
  <a href="https://lookalikeceleb.com"><img alt="Live demo badge" src="https://img.shields.io/badge/Demo-lookalikeceleb.com-4F46E5?logo=vercel"></a>
  <a href="https://docs.inference.net/features/vision"><img alt="Powered by Inference.net" src="https://img.shields.io/badge/Vision%20API-Inference.net-E879F9"></a>
  <img alt="Repo size" src="https://img.shields.io/github/repo-size/yourrepo/lookalikeceleb?color=success">
  <img alt="License" src="https://img.shields.io/github/license/yourrepo/lookalikeceleb">
</p>

---

## ğŸ“¸ 1â€‘Minute Tour

1. **Upload a selfie** (PNGâ€¯/â€¯JPG or paste / camera).
2. The server calls **Inference.net Visionâ€¯+â€¯LLM** â†’ returns structured JSON of your **topâ€‘3 celebrity matches**.
3. Frontâ€‘end fetches hiâ€‘res images for each celeb â†’ renders sideâ€‘byâ€‘side cards with share/download buttons.
4. No account, no storage â€” everything processed in memory.

<br/>

## ğŸ”‘ Why This Repo Rocks

| Problem | How LookalikeCeleb Solves It |
|---------|------------------------------|
| Most lookâ€‘alike apps are blackâ€‘box ğŸ”’ | **Transparent, structured JSON** straight from Inference.net |
| Hard to demo a multimodal LLM quickly | <code>pnpm run dev</code> and you have a fullâ€‘stack vision demo |
| Vision APIs return text blobs | We enforce **JSON schema** â†’ typed data in TS + Zod |
| Shareable results are clunky | Builtâ€‘in **share card generator** (copy, download, social links) |
| Serverless latency issues | Runs on **Bun + Hono** (fast) â€¢ Dockerfile ready â€¢ zero vendor lockâ€‘in |

<br/>

## ğŸ§° Stack

- **Frontend** â€“ Vite â€¢ React 18 â€¢ shadcn/ui â€¢ TailwindCSS  
- **Backend**  â€“ Bun runtime â€¢ Hono router â€¢ TypeScript endâ€‘toâ€‘end  
- **AI**       â€“ [Inference.net VisionÂ API](https://docs.inference.net/features/vision) + StructuredÂ Outputs  
- **Deploy**   â€“ Works on Railway, Vercel, Fly.io, or any Docker host

<br/>

## ğŸš€ Quick Start

```bash
git clone https://github.com/yourrepo/lookalikeceleb.git
cd lookalikeceleb
pnpm install                 # or bun install / npm i
cp .env.example .env         # add INFERENCE_API_KEY
pnpm run dev                 # frontend at http://localhost:5173
bun run server:index.ts      # backend at http://localhost:3000
````

> **Tip:** in dev, Vite proxy is already configured â€” uploads hit <code>/api</code> on portâ€¯3000.

<br/>

## ğŸ› ï¸  Nerdâ€‘Level Architecture

```mermaid
flowchart TD
  A[Client<br/>(React)] -- upload --> B(/api/matches<br/>(Hono+Bun))
  B -- Vision prompt --> C[Inference.net<br/>VisionÂ +Â LLM]
  C -- JSON matches --> B
  B -- fetch img --> D[Y! / Bing Image<br/>SearchÂ Proxy]
  B -- merged JSON --> A
```

*B*: includes timeout + retry logic (handles 524s)
*D*: lightweight proxy â†’ base64 (avoids CORS headaches)

<br/>

## âœ¨ Example Inference RequestÂ â†’ Response

<details>
<summary>Click to view</summary>

**Request (truncated)**

```jsonc
POST https://api.inference.net/v1/chat/completions
{
  "model": "google/gemma-3-27b-instruct/bf-16",
  "messages": [
    {"role":"user","content":[
      { "type":"image_url",
        "image_url":{"url":"data:image/jpeg;base64,..." }
      },
      { "type":"text",
        "text":"Find top 3 celebrity lookâ€‘alikes with explanation."}
    ]}
  ],
  "response_format":{
    "type":"json_schema",
    "json_schema":{
      "type":"object",
      "properties":{
        "matches":{"type":"array","minItems":3,"maxItems":3,
          "items":{
            "type":"object",
            "properties":{
              "name":{"type":"string"},
              "percentage":{"type":"number"},
              "description":{"type":"string"}
            },
            "required":["name","percentage","description"]
          }
        }
      }
    }
  }
}
```

**Response**

```json
{
  "matches": [
    { "name":"Emma Stone","percentage":94,
      "description":"Wide-set green eyes, pronounced cheekbonesâ€¦" },
    { "name":"RyanÂ Gosling","percentage":87,
      "description":"Similar jawline, nose bridge, blue eyesâ€¦" },
    { "name":"Zendaya","percentage":82,
      "description":"Matching eyebrow arch, chin profileâ€¦" }
  ]
}
```

</details>

<br/>

## ğŸŒ 1â€‘Click Deploy

| Platform | Button                                                                                                                                          |
| -------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| Railway  | [![Deploy to Railway](https://railway.app/button.svg)](https://railway.app/new/template?templateUrl=https://github.com/yourrepo/lookalikeceleb) |
| Vercel   | `vercel --prod` works outâ€‘ofâ€‘theâ€‘box                                                                                                            |
| Docker   | `docker build -t lookalikeceleb . && docker run -p 3000:3000 lookalikeceleb`                                                                    |

Set `INFERENCE_API_KEY` wherever you deploy.

<br/>

## ğŸ¤ Contributing

1. Fork + star â­ (optional but awesome)
2. `git checkout -b my-feature`
3. Commit + PR â€” we love community ideas (new share templates? darkâ€‘mode face guide? throw it in!)

<br/>

## ğŸ“œ License

[MIT](LICENSE)

---

> **Built with love for demos, and showing what multimodal LLMs can do.
> If you launch something with this, pingâ€¯me â€” Iâ€™d love to see it!**
